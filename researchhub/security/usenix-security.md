# USENIX Security

## 2023

- **[Gradient Obfuscation Gives a False Sense of Security in Federated Learning.](https://www.usenix.org/system/files/sec23summer_372-yue-prepub.pdf)**
- **[Every Vote Counts: Ranking-Based Training of Federated Learning to Resist Poisoning Attacks.](https://www.usenix.org/system/files/sec23fall-prepub-475-mozaffari.pdf)**
- **[PrivateFL: Accurate, Differentially Private Federated Learning via Personalized Data Transformation.](https://www.usenix.org/system/files/sec23fall-prepub-427-yang-yuchen.pdf)**
- **[VILLAIN: Backdoor Attacks Against Vertical Split Learning.](https://www.usenix.org/system/files/usenixsecurity23-bai.pdf)**

## 2022

- **[SIMC: ML Inference Secure Against Malicious Clients at Semi-Honest Cost.](https://www.usenix.org/system/files/sec22-chandran.pdf)**
- **[Efficient Differentially Private Secure Aggregation for Federated Learning via Hardness of Learning with Errors.](https://www.usenix.org/system/files/sec22-stevens.pdf)**
- **[Label Inference Attacks Against Vertical Federated Learning.](https://www.usenix.org/system/files/sec22-fu-chong.pdf)**
- **[FLAME: Taming Backdoors in Federated Learning.](https://www.usenix.org/system/files/sec22-nguyen.pdf)**

## 2020

- **[Local Model Poisoning Attacks to Byzantine-Robust Federated Learning.](https://www.usenix.org/system/files/sec20-fang.pdf)**
